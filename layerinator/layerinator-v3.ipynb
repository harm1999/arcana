{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def parse_json(json_string):\n",
    "  json_dict = json.loads(json_string)\n",
    "  return json_dict\n",
    "\n",
    "\n",
    "def dict_to_pretty_json(dictionary):\n",
    "  pretty_json = json.dumps(dictionary, indent=2)\n",
    "  return pretty_json\n",
    "\n",
    "\n",
    "def write_dict_to_json(dictionary, file_path):\n",
    "  with open(file_path, 'w') as json_file:\n",
    "    json.dump(dictionary, json_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "def read_ini_file(file_path):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(file_path)\n",
    "    ini_dict = {section: dict(config.items(section))\n",
    "                for section in config.sections()}\n",
    "    return ini_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def remove_java_comments(java_source):\n",
    "    # Regular expression to match Java comments (both single-line and multi-line)\n",
    "    pattern = r\"(//.*?$)|(/\\*.*?\\*/)\"\n",
    "\n",
    "    # Remove comments using the regular expression\n",
    "    java_source_without_comments = re.sub(\n",
    "        pattern, \"\", java_source, flags=re.MULTILINE | re.DOTALL)\n",
    "\n",
    "    return java_source_without_comments.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence(s):\n",
    "  '''\n",
    "  Capitalize the first letter of a string `s` and ensures that the string \n",
    "  ends with a period (if it's not already a sentence-ending punctuation).\n",
    "  '''\n",
    "  t = s.strip()\n",
    "  if t[-1] in '.?!…~–—':\n",
    "    return f'{t[0].upper()}{t[1:]}'\n",
    "  else:\n",
    "    return f'{t[0].upper()}{t[1:]}.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_graph(graph):\n",
    "\tnodes = { node['data']['id']: node['data'] for node in graph['elements']['nodes'] }\n",
    "\tedges = {}\n",
    "\tfor edge in graph['elements']['edges']:\n",
    "\t\tif 'label' in edge['data']:\n",
    "\t\t\tlabel = edge['data']['label']\n",
    "\t\telse:\n",
    "\t\t\tlabel = ','.join(edge['data']['labels'])\n",
    "\t\t\tedge['data']['label'] = label\n",
    "\t\t\n",
    "\t\tif label not in edges:\n",
    "\t\t\tedges[label] = []\n",
    "\t\tedges[label].append(edge['data'])\n",
    "\treturn (nodes, edges)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert(edgeList):\n",
    "    prefix = \"inv_\"\n",
    "    invertedEdges = []\n",
    "    for edge in edgeList:\n",
    "        invertedEdge = {\n",
    "            'source': edge['target'],\n",
    "            'target': edge['source'],\n",
    "            'label': prefix + edge.get('label', ''),\n",
    "            **{key: value for key, value in edge.items() if key not in ['source', 'target', 'label']}\n",
    "        }\n",
    "        invertedEdges.append(invertedEdge)\n",
    "    return invertedEdges\n",
    "\n",
    "def find_paths(edgeList1, edgeList2):\n",
    "    source_mapping = {}\n",
    "    for edge in edgeList1:\n",
    "        source_mapping[edge['target']] = edge['source']\n",
    "\n",
    "    paths = set()\n",
    "    for edge in edgeList2:\n",
    "        if edge['source'] in source_mapping:\n",
    "            source1 = source_mapping[edge['source']]\n",
    "            path = [source1, edge['source'], edge['target']]\n",
    "            paths.add(tuple(path))\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If True: do not call the API, just print the prompts\n",
    "only_print_prompt = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets = read_ini_file('config.ini')\n",
    "project_name = secrets['project']['name']\n",
    "project_desc = secrets['project']['desc']\n",
    "ifile = secrets['project']['ifile']\n",
    "(project_name,project_desc,ifile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read graph file\n",
    "\n",
    "To access knowledge graph extracted using javapers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = read_json_file(ifile)\n",
    "nodes,edges = transform_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliet_args = dict()\n",
    "\n",
    "if 'apikey' in secrets['openai']:\n",
    "  cliet_args['api_key'] = secrets['openai']['apikey']\n",
    "if 'apibase' in secrets['openai']:\n",
    "  cliet_args['base_url'] = secrets['openai']['apibase']\n",
    "if 'model' in secrets['openai']:\n",
    "  model = secrets['openai']['model']\n",
    "else:\n",
    "  model = \"gpt-3.5-turbo\"\n",
    "\n",
    "(list(cliet_args.keys()), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(**cliet_args)\n",
    "client.base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the LLM server---create a completion\n",
    "completion = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[{\"role\":\"user\",\"content\":\"What is your name?\"}],\n",
    "  temperature=0\n",
    ")\n",
    "# print the completion\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elements to be inspected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = sorted([(pkg_id,cls_id,met_id) for pkg_id,cls_id,met_id in find_paths(edges['contains'], edges['hasScript']) if nodes[met_id]['properties']['visibility']=='public'])\n",
    "len(methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted({(pkg,clz) for pkg,clz,_ in methods})\n",
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = sorted({pkg for pkg,_ in classes})\n",
    "len(packages),packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {pkg_id:{\n",
    "\t'qualifiedName': nodes[pkg_id]['properties']['qualifiedName'],\n",
    "\t'classes': {cls_id: {\n",
    "\t\t'qualifiedName': nodes[cls_id]['properties']['qualifiedName'],\n",
    "\t\t'methods': {met_id: {\n",
    "\t\t\t'qualifiedName': nodes[met_id]['properties']['qualifiedName']\n",
    "\t\t} for _,c,met_id in methods if c == cls_id}\n",
    "\t} for p,cls_id in classes if p == pkg_id}\n",
    "} for pkg_id in packages}\n",
    "\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask LLM to classify methods into layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1_template = '''Here are the layers in a layered software architecture and their responsibilities:\n",
    "\n",
    "1. **Presentation Layer**: Manages the user interface, including defining UI elements and their behavior, displays information, reacts to user input, and updates UI views accordingly.\n",
    "  \n",
    "2. **Service Layer**: Orchestrates domain operations, encapsulates business logic, selects the appropriate business logic for a user request, and coordinates responses between the presentation and domain layers.\n",
    "\n",
    "3. **Domain Layer**: Organizes and implements business logic, represents domain data and its behavior, and carries out the necessary computation for responding to user requests.\n",
    "\n",
    "4. **Data Source Layer**: Communicates with databases, messaging systems, or other sources of data, performs CRUD operations, handles data conversion, and ensures data integrity before committing changes to the data source.\n",
    "\n",
    "**Project Context**: {project_desc}\n",
    "\n",
    "Consider the following Java method from the project:\n",
    "\n",
    "```java\n",
    "{method_src}\n",
    "```\n",
    "\n",
    "**Task**:\n",
    "\n",
    "1. **Summarize the Method**: Briefly describe the primary responsibility of this method.\n",
    "2. **Layer Comparison**: Compare the method's functionality to each of the layers described above. Determine which layer it best fits into and explain why. Consider the context of the project when determining the layer placement.\n",
    "3. **Multiple Layers Assignment**: If you assigned the method to more than one layer, evaluate each assigned layer. Argue with yourself about which one of these layers fits the method best. Provide clear reasoning for your final decision.\n",
    "4. **Single Layer Assignment**: If you assigned the method to only one layer, justify your choice. Convince me why this is the correct layer by providing specific examples and reasoning.  \n",
    "5. **No Layer Assignment**: If you did not assign the method to any layer, reconsider your decision. Reflect on whether the method truly lies outside the defined layers (in such case, answer with \"Cross-cutting) or if it leans towards one of the layers. Explain your reasoning.'''\n",
    "\n",
    "prompt2 = \"In conclusion, state the single layer that you think fits this method the most. Just answer with the name of the layer and nothing else.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "timestr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestr = '20240522-120247'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'layerinator-{timestr}.log', 'a') as file:\n",
    "\n",
    "    kind = 'class'\n",
    "    current_pkg = None\n",
    "    current_cls = None\n",
    "    for pkg_id,cls_id,met_id in methods[:10]:\n",
    "            \n",
    "        if current_pkg != pkg_id:\n",
    "            if current_pkg:\n",
    "                file.write('\\n\\n===============================================\\n\\n')\n",
    "                \n",
    "            last_pkg = current_pkg\n",
    "            current_pkg = pkg_id\n",
    "            file.write('# ' + current_pkg + \"\\n\")\n",
    "        \n",
    "        if current_cls != cls_id:\n",
    "            file.flush()\n",
    "            last_cls = current_cls\n",
    "            current_cls = cls_id\n",
    "            file.write('\\t* ' + current_cls + \"\\n\")\n",
    "\n",
    "        if not 'layer' in results[pkg_id]['classes'][cls_id]['methods'][met_id] \\\n",
    "                or results[pkg_id]['classes'][cls_id]['methods'][met_id]['layer'] == 'undefined':\n",
    "\n",
    "            file.write('\\t\\t- ' + met_id + \"\\n\")\n",
    "\n",
    "            package = nodes[pkg_id]\n",
    "            clasz = nodes[cls_id]\n",
    "            method = nodes[met_id]\n",
    "\n",
    "            method_name = method['properties']['simpleName']\n",
    "            \n",
    "            prompt1 = prompt1_template.format(\n",
    "                project_desc=project_desc,\n",
    "                method_src=method['properties'][\"sourceText\"]\n",
    "            )\n",
    "            if only_print_prompt:\n",
    "                file.write('\\t\\t\\t' + prompt1)\n",
    "                file.write(\"\\n\\n\")\n",
    "            else:\n",
    "                response = None\n",
    "                try:\n",
    "                    response = client.chat.completions.create(\n",
    "                        model=model,\n",
    "                        messages=[{\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": prompt1\n",
    "                        }],\n",
    "                        temperature=0)\n",
    "                    ast_message = response.choices[0].message\n",
    "                    \n",
    "                    file.write('\\t\\t\\t' + \"[USER]\\n\\n\")\n",
    "                    file.write('\\t\\t\\t' + prompt1)\n",
    "                    file.write(\"\\n\\n\")\n",
    "                    file.write('\\t\\t\\t' + \"[LLM]\\n\\n\")\n",
    "                    file.write('\\t\\t\\t' + ast_message.content)\n",
    "                    file.write(\"\\n\\n\")\n",
    "\n",
    "                    response = client.chat.completions.create(\n",
    "                        model=model,\n",
    "                        messages=[{\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": prompt1\n",
    "                        }, \n",
    "                        ast_message,\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": prompt2\n",
    "                        }],\n",
    "                        temperature=0)\n",
    "                    answer = response.choices[0].message.content\n",
    "                    \n",
    "                    file.write('\\t\\t\\t' + \"[USER]\\n\\n\")\n",
    "                    file.write('\\t\\t\\t' + prompt2)\n",
    "                    file.write(\"\\n\\n\")\n",
    "                    file.write('\\t\\t\\t' + \"[LLM]\\n\\n\")\n",
    "                    file.write('\\t\\t\\t' + answer)\n",
    "                    file.write(\"\\n\\n\")\n",
    "\n",
    "                    results[pkg_id]['classes'][cls_id]['methods'][met_id]['layer'] = answer\n",
    "                except:\n",
    "                    answer = None\n",
    "                    file.write('\\t\\t\\t' + (str(response) if response else \"no response\"))\n",
    "                    file.write(\"\\n\\n\")\n",
    "                    results[pkg_id]['classes'][cls_id]['methods'][met_id]['layer'] = \"undefined\"\n",
    "                    \n",
    "            file.write(\"\\n\\n\")\n",
    "\n",
    "    file.write(\"ALL RESULTS:\\n\\n\")\n",
    "    file.write(dict_to_pretty_json(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not only_print_prompt:\n",
    "  write_dict_to_json(results, f\"{project_name}-layers-{timestr}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = read_json_file(f\"{project_name}-layers-20240522-120247.json\")\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_layer_occurrences(input_dict):\n",
    "    layer_count = {}\n",
    "\n",
    "    for _, details in input_dict.items():\n",
    "        layer = details.get(\"layer\")\n",
    "        if layer:\n",
    "            if layer in layer_count:\n",
    "                layer_count[layer] += 1\n",
    "            else:\n",
    "                layer_count[layer] = 1\n",
    "\n",
    "    return layer_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pkg_id in results:\n",
    "\tfor cls_id in results[pkg_id]['classes']:\n",
    "\t\tresults[pkg_id]['classes'][cls_id]['layers'] = count_layer_occurrences(results[pkg_id]['classes'][cls_id]['methods'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_layer_counts(input_dicts):\n",
    "    layer_count = {}\n",
    "\n",
    "    for _, details in input_dicts.items():\n",
    "        layers = details.get(\"layers\", {})\n",
    "        for layer, count in layers.items():\n",
    "            if layer in layer_count:\n",
    "                layer_count[layer] += count\n",
    "            else:\n",
    "                layer_count[layer] = count\n",
    "\n",
    "    return layer_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pkg_id in results:\n",
    "\tresults[pkg_id]['layers'] = sum_layer_counts(results[pkg_id]['classes'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dict_to_json(results, f\"{project_name}-layers-recap-{timestr}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for pkg_id in results:\n",
    "\tfor cls_id in [c for c in results[pkg_id]['classes']]:\n",
    "\t\tfor met_id in [m for m in results[pkg_id]['classes'][cls_id]['methods']]:\n",
    "\t\t\trows.append((pkg_id,cls_id,met_id,results[pkg_id]['classes'][cls_id]['methods'][met_id]['layer']))\n",
    "\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = (\"package\", \"class\", \"method\", \"layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(f\"{project_name}-layers1-{timestr}.csv\", mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for pkg_id in results:\n",
    "\tfor cls_id in [c for c in results[pkg_id]['classes']]:\n",
    "\t\tfor layer in results[pkg_id]['classes'][cls_id]['layers']:\n",
    "\t\t\trows.append((pkg_id,cls_id,layer,results[pkg_id]['classes'][cls_id]['layers'][layer]))\n",
    "\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = (\"package\", \"class\", \"layer\", \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(f\"{project_name}-layers2-{timestr}.csv\", mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for pkg_id in results:\n",
    "\tfor cls_id in [c for c in results[pkg_id]['classes']]:\n",
    "\t\tfor layer in results[pkg_id]['classes'][cls_id]['layers']:\n",
    "\t\t\trows.append((pkg_id,cls_id,layer,results[pkg_id]['classes'][cls_id]['layers'][layer]/sum(results[pkg_id]['classes'][cls_id]['layers'].values())))\n",
    "\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(f\"{project_name}-layers3-{timestr}.csv\", mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
